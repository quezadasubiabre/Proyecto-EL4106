{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load vgg16.py\n",
    "import inspect\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "VGG_MEAN = [103.939, 116.779, 123.68]\n",
    "\n",
    "\n",
    "class Vgg16:\n",
    "    def __init__(self, vgg16_npy_path=None):\n",
    "        if vgg16_npy_path is None:\n",
    "            path = inspect.getfile(Vgg16)\n",
    "            path = os.path.abspath(os.path.join(path, os.pardir))\n",
    "            path = os.path.join(path, \"vgg16.npy\")\n",
    "            vgg16_npy_path = path\n",
    "            print(path)\n",
    "\n",
    "        self.data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n",
    "        print(\"npy file loaded\")\n",
    "\n",
    "    def build(self, rgb):\n",
    "        \"\"\"\n",
    "        load variable from npy to build the VGG\n",
    "\n",
    "        :param rgb: rgb image [batch, height, width, 3] values scaled [0, 1]\n",
    "        \"\"\"\n",
    "\n",
    "        start_time = time.time()\n",
    "        print(\"build model started\")\n",
    "        rgb_scaled = rgb * 255.0\n",
    "\n",
    "        # Convert RGB to BGR\n",
    "        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=rgb_scaled)\n",
    "        assert red.get_shape().as_list()[1:] == [224, 224, 1]\n",
    "        assert green.get_shape().as_list()[1:] == [224, 224, 1]\n",
    "        assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n",
    "        bgr = tf.concat(axis=3, values=[\n",
    "            blue - VGG_MEAN[0],\n",
    "            green - VGG_MEAN[1],\n",
    "            red - VGG_MEAN[2],\n",
    "        ])\n",
    "        assert bgr.get_shape().as_list()[1:] == [224, 224, 3]\n",
    "\n",
    "        self.conv1_1 = self.conv_layer(bgr, \"conv1_1\")\n",
    "        self.conv1_2 = self.conv_layer(self.conv1_1, \"conv1_2\")\n",
    "        self.pool1 = self.max_pool(self.conv1_2, 'pool1')\n",
    "\n",
    "        self.conv2_1 = self.conv_layer(self.pool1, \"conv2_1\")\n",
    "        self.conv2_2 = self.conv_layer(self.conv2_1, \"conv2_2\")\n",
    "        self.pool2 = self.max_pool(self.conv2_2, 'pool2')\n",
    "\n",
    "        self.conv3_1 = self.conv_layer(self.pool2, \"conv3_1\")\n",
    "        self.conv3_2 = self.conv_layer(self.conv3_1, \"conv3_2\")\n",
    "        self.conv3_3 = self.conv_layer(self.conv3_2, \"conv3_3\")\n",
    "        self.pool3 = self.max_pool(self.conv3_3, 'pool3')\n",
    "\n",
    "        self.conv4_1 = self.conv_layer(self.pool3, \"conv4_1\")\n",
    "        self.conv4_2 = self.conv_layer(self.conv4_1, \"conv4_2\")\n",
    "        self.conv4_3 = self.conv_layer(self.conv4_2, \"conv4_3\")\n",
    "        self.pool4 = self.max_pool(self.conv4_3, 'pool4')\n",
    "\n",
    "        self.conv5_1 = self.conv_layer(self.pool4, \"conv5_1\")\n",
    "        self.conv5_2 = self.conv_layer(self.conv5_1, \"conv5_2\")\n",
    "        self.conv5_3 = self.conv_layer(self.conv5_2, \"conv5_3\")\n",
    "        self.pool5 = self.max_pool(self.conv5_3, 'pool5')\n",
    "\n",
    "        self.fc6 = self.fc_layer(self.pool5, \"fc6\")\n",
    "        assert self.fc6.get_shape().as_list()[1:] == [4096]\n",
    "        self.relu6 = tf.nn.relu(self.fc6)\n",
    "\n",
    "        self.fc7 = self.fc_layer(self.relu6, \"fc7\")\n",
    "        self.relu7 = tf.nn.relu(self.fc7)\n",
    "\n",
    "        self.fc8 = self.fc_layer(self.relu7, \"fc8\")\n",
    "\n",
    "        self.prob = tf.nn.softmax(self.fc8, name=\"prob\")\n",
    "\n",
    "        self.data_dict = None\n",
    "        print((\"build model finished: %ds\" % (time.time() - start_time)))\n",
    "\n",
    "    def avg_pool(self, bottom, name):\n",
    "        return tf.nn.avg_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "    def max_pool(self, bottom, name):\n",
    "        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "    def conv_layer(self, bottom, name):\n",
    "        with tf.variable_scope(name):\n",
    "            filt = self.get_conv_filter(name)\n",
    "\n",
    "            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "            conv_biases = self.get_bias(name)\n",
    "            bias = tf.nn.bias_add(conv, conv_biases)\n",
    "\n",
    "            relu = tf.nn.relu(bias)\n",
    "            return relu\n",
    "\n",
    "    def fc_layer(self, bottom, name):\n",
    "        with tf.variable_scope(name):\n",
    "            shape = bottom.get_shape().as_list()\n",
    "            dim = 1\n",
    "            for d in shape[1:]:\n",
    "                dim *= d\n",
    "            x = tf.reshape(bottom, [-1, dim])\n",
    "\n",
    "            weights = self.get_fc_weight(name)\n",
    "            biases = self.get_bias(name)\n",
    "\n",
    "            # Fully connected layer. Note that the '+' operation automatically\n",
    "            # broadcasts the biases.\n",
    "            fc = tf.nn.bias_add(tf.matmul(x, weights), biases)\n",
    "\n",
    "            return fc\n",
    "\n",
    "    def get_conv_filter(self, name):\n",
    "        return tf.constant(self.data_dict[name][0], name=\"filter\")\n",
    "\n",
    "    def get_bias(self, name):\n",
    "        return tf.constant(self.data_dict[name][1], name=\"biases\")\n",
    "\n",
    "    def get_fc_weight(self, name):\n",
    "        return tf.constant(self.data_dict[name][0], name=\"weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\queza\\Documents\\Anaconda\\envs\\keras\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\queza\\Documents\\Anaconda\\envs\\keras\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\queza\\Documents\\Anaconda\\envs\\keras\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\queza\\Documents\\GitHub\\Proyecto-EL4106\\Entrega_2\\modelo_python\\vgg16.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 17s\n",
      "[[2.3465678e-09 1.0315247e-11 3.4354231e-11 ... 6.1144645e-11\n",
      "  3.7294456e-10 2.1108960e-10]\n",
      " [2.7882580e-08 4.0970730e-07 1.0288739e-08 ... 1.1415134e-07\n",
      "  6.3490205e-08 1.5433030e-05]]\n",
      "('Top1: ', 'n02504458 African elephant, Loxodonta africana', 0.5343758)\n",
      "('Top5: ', [('n02504458 African elephant, Loxodonta africana', 0.5343758), ('n01871265 tusker', 0.33254465), ('n02504013 Indian elephant, Elephas maximus', 0.13303517), ('n01704323 triceratops', 3.5053836e-05), ('n02408429 water buffalo, water ox, Asiatic buffalo, Bubalus bubalis', 2.6646087e-06)])\n",
      "('Top1: ', 'n03598930 jigsaw puzzle', 0.9959151)\n",
      "('Top5: ', [('n03598930 jigsaw puzzle', 0.9959151), ('n03291819 envelope', 0.00028725123), ('n03908618 pencil box, pencil case', 0.00022548522), ('n03188531 diaper, nappy, napkin', 0.00021818104), ('n04033995 quilt, comforter, comfort, puff', 0.00018459375)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import vgg16\n",
    "import utils\n",
    "\n",
    "img1 = utils.load_image(\"./test_data/elefante.jpg\")\n",
    "img2 = utils.load_image(\"./test_data/puzzle.jpeg\")\n",
    "\n",
    "batch1 = img1.reshape((1, 224, 224, 3))\n",
    "batch2 = img2.reshape((1, 224, 224, 3))\n",
    "\n",
    "batch = np.concatenate((batch1, batch2), 0)\n",
    "\n",
    "# with tf.Session(config=tf.ConfigProto(gpu_options=(tf.GPUOptions(per_process_gpu_memory_fraction=0.7)))) as sess:\n",
    "with tf.device('/cpu:0'):\n",
    "    with tf.Session() as sess:\n",
    "        images = tf.placeholder(\"float\", [2, 224, 224, 3])\n",
    "        feed_dict = {images: batch}\n",
    "\n",
    "        vgg = vgg16.Vgg16()\n",
    "        with tf.name_scope(\"content_vgg\"):\n",
    "            vgg.build(images)\n",
    "\n",
    "        prob = sess.run(vgg.prob, feed_dict=feed_dict)\n",
    "        print(prob)\n",
    "        utils.print_prob(prob[0], './synset.txt')\n",
    "        utils.print_prob(prob[1], './synset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'content_vgg/pool4:0' shape=(2, 14, 14, 512) dtype=float32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.pool4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
